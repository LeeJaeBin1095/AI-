{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.model_selection import KFold, StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 데이터 불러오기\n",
    "df_org = pd.read_csv(\"train.csv\", encoding=\"cp949\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_org.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 범주형 변수 수치화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nan 값 처리\n",
    "df_org = df_org.fillna('없음')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 범주형 변수를 수치형 변수로 바꾸기 위한 작업 \n",
    "# 범주형 변수의 고유값 별 개수를 df_z로 따로 저장\n",
    "df_z = df_org['특송업체부호'].value_counts(normalize=True).rename_axis('unique').reset_index(name='counts')\n",
    "# df_z에서 각각의 cloumns을 분리해서 별도로 저장 \n",
    "df_un = df_z['unique']\n",
    "df_co = df_z['counts'].round(decimals=6)\n",
    "du = df_un.tolist()\n",
    "dc = df_co.tolist()\n",
    "# 본래 데이터에 새롭게 추가\n",
    "for i in range(df_z.shape[0]):\n",
    "    df_org.loc[df_org['특송업체부호'] == du[i] , '특송업체부호비율'] = dc[i]\n",
    "# 수치형 변수 타입 변경 \n",
    "df_org['특송업체부호비율'] = df_org['특송업체부호비율'].apply(lambda x: np.log1p(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_z = df_org['통관지세관부호'].value_counts(normalize=True).rename_axis('unique').reset_index(name='counts')\n",
    "df_un = df_z['unique']\n",
    "df_co = df_z['counts'].round(decimals=6)\n",
    "du = df_un.tolist()\n",
    "dc = df_co.tolist()\n",
    "for i in range(df_z.shape[0]):\n",
    "    df_org.loc[df_org['통관지세관부호'] == du[i] , '통관지세관부호비율'] = dc[i]\n",
    "df_org['통관지세관부호비율'] = df_org['통관지세관부호비율'].apply(lambda x: np.log1p(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_z = df_org['해외거래처부호'].value_counts(normalize=True).rename_axis('unique').reset_index(name='counts')\n",
    "df_un = df_z['unique']\n",
    "df_co = df_z['counts'].round(decimals=6)\n",
    "du = df_un.tolist()\n",
    "dc = df_co.tolist()\n",
    "for i in range(df_z.shape[0]):\n",
    "    df_org.loc[df_org['해외거래처부호'] == du[i] , '해외거래처부호비율'] = dc[i]\n",
    "df_org['해외거래처부호비율'] = df_org['해외거래처부호비율'].apply(lambda x: np.log1p(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_z = df_org['운송수단유형코드'].value_counts(normalize=True).rename_axis('unique').reset_index(name='counts')\n",
    "df_un = df_z['unique']\n",
    "df_co = df_z['counts'].round(decimals=6)\n",
    "du = df_un.tolist()\n",
    "dc = df_co.tolist()\n",
    "for i in range(df_z.shape[0]):\n",
    "    df_org.loc[df_org['운송수단유형코드'] == du[i] , '운송수단유형코드비율'] = dc[i]\n",
    "df_org['운송수단유형코드비율'] = df_org['운송수단유형코드비율'].apply(lambda x: np.log1p(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#추가된 수치형 변수 확인 \n",
    "df_org.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 변수 Drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필요없다고 생각하는 column 삭제\n",
    "del df_org['통관지세관부호']\n",
    "del df_org['특송업체부호']\n",
    "del df_org['해외거래처부호']\n",
    "del df_org['운송수단유형코드']\n",
    "del df_org['신고일자']\n",
    "del df_org['검사결과코드']\n",
    "del df_org['핵심적발']\n",
    "del df_org['신고인부호']\n",
    "del df_org['신고번호']\n",
    "del df_org['원산지국가코드']\n",
    "del df_org['관세율']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#삭제후 데이터셋의 column 확인 \n",
    "df_org.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 범주형 변수 지정\n",
    "discrete_columns = ['수입자부호', '수입통관계획코드', \n",
    "       '수입신고구분코드', '수입거래구분코드',\n",
    "       '수입종류코드', '징수형태코드', \n",
    "       '반입보세구역부호', \n",
    "       'HS10단위부호', '적출국가코드', '관세율구분코드']\n",
    "\n",
    "# 범주형 변수들을 문자열로 지정 ('object' -> 'string')\n",
    "for var in discrete_columns:\n",
    "    df_org[var] = df_org[var].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 레이블 인코딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 범주형 변수 전처리 1단계: label encoding --> 각 범주형 변수가 갖는 클래스에 고유의 식별번호 부여\n",
    "# 예) 수입자 상호: AAABB -> 1, 가나다라 -> 2, ...\n",
    "\n",
    "label_encoding_ref = {}\n",
    "for var in discrete_columns:\n",
    "    label_encoding_ref[var] = {code: i+1 for i, code in enumerate(df_org[var].unique())}\n",
    "    print(label_encoding_ref[var])\n",
    "    df_org[var] = [label_encoding_ref[var][x] for x in df_org[var]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_org.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 수치형 변수 지정\n",
    "numeric_columns = ['신고중량(KG)', '과세가격원화금액', '특송업체부호비율', \n",
    "                   '통관지세관부호비율', '해외거래처부호비율', '운송수단유형코드비율']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 수치형 변수, 범주형 변수 분리\n",
    "numeric = df_org[numeric_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 수치형 변수 정규화\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "std_scaler = StandardScaler()\n",
    "rob_scaler = RobustScaler()\n",
    "\n",
    "numeric['신고중량(KG)'] = rob_scaler.fit_transform(numeric['신고중량(KG)'].values.reshape(-1,1))\n",
    "numeric['과세가격원화금액'] = rob_scaler.fit_transform(numeric['과세가격원화금액'].values.reshape(-1,1))\n",
    "numeric['특송업체부호비율'] = rob_scaler.fit_transform(numeric['특송업체부호비율'].values.reshape(-1,1))\n",
    "numeric['통관지세관부호비율'] = rob_scaler.fit_transform(numeric['통관지세관부호비율'].values.reshape(-1,1))\n",
    "numeric['해외거래처부호비율'] = rob_scaler.fit_transform(numeric['해외거래처부호비율'].values.reshape(-1,1))\n",
    "numeric['운송수단유형코드비율'] = rob_scaler.fit_transform(numeric['운송수단유형코드비율'].values.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_org.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 수치형 PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import decomposition\n",
    "#주성분 갯수 5개  생성 \n",
    "pca = decomposition.PCA(n_components=5).fit(numeric)\n",
    "\n",
    "reduced_numeric = pca.transform(numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#수치형 변수에 대해서 PCA 계산\n",
    "df_org['신고중량(KG)']  = reduced_numeric[:, 0]\n",
    "df_org['과세가격원화금액']  = reduced_numeric[:, 1]\n",
    "df_org['특송업체부호비율']  = reduced_numeric[:, 2]\n",
    "df_org['통관지세관부호비율']  = reduced_numeric[:, 2]\n",
    "df_org['해외거래처부호비율']  = reduced_numeric[:, 3]\n",
    "df_org['운송수단유형코드비율']  = reduced_numeric[:, 4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터셋 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA 처리 제대로 되었는지 확인\n",
    "df_org.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 훈련/시험 데이터셋 분할"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 셋 라벨 분리\n",
    "y = df_org['우범여부']\n",
    "x = df_org.drop(columns = '우범여부')\n",
    "type(x), type(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train, test data split\n",
    "df_org_train, df_org_test, org_train_y, org_test_y = train_test_split(x,y, test_size = 0.3, stratify = y, random_state =3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 원핫인코딩 데이터셋 프로세스"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train, test data 원핫인코딩 전 마킹\n",
    "df_org_train['label'] = 'train'\n",
    "df_org_test['label'] = 'test'\n",
    "# train, test data 결합\n",
    "concat_df = pd.concat([df_org_train,df_org_test])\n",
    "\n",
    "# dummies함수를 통해 범주형 변수 원핫인코딩\n",
    "df_org_trains = pd.get_dummies(concat_df, columns = discrete_columns)\n",
    "\n",
    "# 마킹값을 통해 train, test data 복구\n",
    "df_train =  df_org_trains[df_org_trains['label'] == 'train']\n",
    "df_test =  df_org_trains[df_org_trains['label'] == 'test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 마킹 라벨 제거\n",
    "df_train = df_train.drop('label', axis=1)\n",
    "df_test = df_test.drop('label', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 사이즈 확인\n",
    "print(df_train.shape, df_test.shape)\n",
    "print(org_train_y.shape, org_test_y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imbalanced Sampling\n",
    "# * SMOTE *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SMOTE를 진행할 train data 확인\n",
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SMOTE를 통해 train data 클래스 불균형 해결\n",
    "smote = SMOTE(random_state=11, sampling_strategy='all')\n",
    "df_train_over_x, df_train_over_y = smote.fit_resample(df_train, org_train_y)\n",
    "df_train_over_x.info(), df_train_over_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델 생성 / 학습 / 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost 모델 생성\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import f1_score,roc_auc_score\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# xgb 모델 생성\n",
    "xgb_clf = XGBClassifier(n_estimators=50, max_depth=4, n_jobs=-1, reg_lambda=1)\n",
    "# evaluation Set 생성\n",
    "eval_set = [(df_train_over_x, df_train_over_y), (df_test, org_test_y)]\n",
    "# 모델 학습\n",
    "xgb_clf.fit(df_train_over_x, df_train_over_y, eval_metric=[\"logloss\"],\n",
    "            eval_set=eval_set, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 성능 시각화\n",
    "\n",
    "from matplotlib import pyplot\n",
    "# retrieve performance metrics\n",
    "results = xgb_clf.evals_result()\n",
    "epochs = len(results['validation_0']['logloss'])\n",
    "x_axis = range(0, epochs)\n",
    "# plot log loss\n",
    "fig, ax = pyplot.subplots()\n",
    "ax.plot(x_axis, results['validation_0']['logloss'], label='Train')\n",
    "ax.plot(x_axis, results['validation_1']['logloss'], label='Test')\n",
    "ax.legend()\n",
    "pyplot.ylabel('Log Loss')\n",
    "pyplot.title('XGBoost Log Loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate xgboost model\n",
    "print(\"------Evaluating xgboost model------\")\n",
    "# Predict\n",
    "test_pred = xgb_clf.predict_proba(df_test)[:,1]\n",
    "# Calculate auc\n",
    "xgb_auc = roc_auc_score(org_test_y, test_pred)\n",
    "print(xgb_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspection 검사 함수\n",
    "def inspection_performance(predicted_fraud, test_fraud):\n",
    "        \n",
    "    Inspect_Rate=[]\n",
    "    Precision=[]\n",
    "    Recall=[]\n",
    "    \n",
    "    for i in range(0,101,1):\n",
    "        \n",
    "        threshold = np.percentile(predicted_fraud, i)\n",
    "        # Precision = number of frauds / number of inspection\n",
    "        precision = np.mean(test_fraud[predicted_fraud >= threshold])\n",
    "        # Recall = number of inspected frauds / number of frauds\n",
    "        recall = sum(test_fraud[predicted_fraud >= threshold])/sum(test_fraud)\n",
    "        # Save values\n",
    "        Inspect_Rate.append(100-i)\n",
    "        Precision.append(precision)\n",
    "        Recall.append(recall)\n",
    "        \n",
    "    \n",
    "    compiled_conf_matrix = pd.DataFrame({\n",
    "        'Inspect_Rate':Inspect_Rate,\n",
    "        'Precision':Precision,\n",
    "        'Recall':Recall\n",
    "    })\n",
    "\n",
    "    return compiled_conf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspection 계산\n",
    "basic_performance = inspection_performance(test_pred, org_test_y.astype(float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 검사율 1~10% 지정 시 Precision 및 Recall 분석\n",
    "# Precision (적중률) = (검사선별된 우범건수)/(검사선별 건수)\n",
    "# Recall (적발률) = (검사선별된 우범건수) / (전체 우범건수)\n",
    "basic_performance.iloc[range(99,89,-1),:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 계산한 결과 시각화\n",
    "data = pd.melt(basic_performance, \n",
    "               id_vars = ['Inspect_Rate'],\n",
    "               value_vars = ['Recall','Precision'])\n",
    "\n",
    "sns.relplot(data=data,\n",
    "            kind='line',\n",
    "            x=\"Inspect_Rate\", \n",
    "            y=\"value\", \n",
    "            hue='variable',\n",
    "            col=\"variable\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 모델에 기여도가 높은 변수 시각화\n",
    "from xgboost import plot_importance\n",
    "plt.rcParams[\"font.family\"] = 'Malgun Gothic'\n",
    "plt.rcParams[\"figure.figsize\"] = (15,10)\n",
    "plot_importance(xgb_clf, max_num_features=30)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test 예측 label 값 \n",
    "y_preds = xgb_clf.predict(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"accuracy score for trained data\",accuracy_score(df_train_over_y,xgb_clf.predict(df_train_over_x)))\n",
    "print(\"accuracy score is\",accuracy_score(org_test_y,y_preds))\n",
    "print(\"Confusion matrix\",confusion_matrix(org_test_y,y_preds))\n",
    "print(\"Report\",classification_report(org_test_y,y_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission 값 추출"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submission 용 Test 데이터셋 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_org를 불러올 때 기존 train + test 셋을 합쳐서 불러옴\n",
    "# 불러온 후 기존에 있던 데이터 전처리 모두 시행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train + Test의 데이터를 전부 One Hot encoding 시행\n",
    "df_onehot = pd.get_dummies(df_org, columns = discrete_columns)\n",
    "df_onehot.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 인코딩한 데이터프레임을 분리하여 'test' 데이터프레임은 유지\n",
    "# 분리한 이후 남은 train 셋은 기존에 인코딩 프로세스로 진행\n",
    "\n",
    "test = df_onehot.iloc[76837:, :]\n",
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 분리한 테스트셋의 레이블 삭제\n",
    "\n",
    "test_x = real_test.drop(columns='우범여부')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습시킨 기존 모델에 'test' 데이터프레임 대상으로 predict 시행\n",
    "\n",
    "y_preds = xgb_clf.predict(test_x)\n",
    "y_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예측결과 데이터프레임 변환 \n",
    "\n",
    "pred_df = pd.DataFrame(y_preds, columns=['우범여부'])\n",
    "pred_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예측결과 데이터프레임 csv파일 변환\n",
    "\n",
    "pred_df.to_csv('C:\\\\Users\\\\CEO\\\\result.csv', index = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
